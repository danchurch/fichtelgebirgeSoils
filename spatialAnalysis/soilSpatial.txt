## git our local copy of the repo in order for office comp.
## working off the work tower, so need to get git synced up now to
## avoid confusion.

## we need RSA with SHA-2 signature algorithm

man ssh-keygen
ssh-keygen -t rsa -f fuj2git

## now, what do we need to get the push functionality...

git clone https://github.com/danchurch/fichtelgebirgeSoils.git

## test

touch thisIsNotReal.txt

## and of course can't push

git config --global user.email "danchurchthomas@gmail.com"
git config --global user.name "danchurch"

git remote add origin https://github.com/danchurch/fichtelgebirgeSoils.git
git branch -M main
git remote set-url origin git@github.com:danchurch/fichtelgebirgeSoils.git
git push -u origin main

## and we're in business with github

## maybe let's get a conda environment going for this.

wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh

mkdir -p ~/miniconda3
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh
bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3
rm -rf ~/miniconda3/miniconda.sh
~/miniconda3/bin/conda init bash

conda config --set auto_activate_base false

## get the mamba solver:

conda update -n base conda
conda install -n base conda-libmamba-solver
conda config --set solver libmamba

## get the standard channels
conda config --add channels defaults
conda config --add channels bioconda
conda config --add channels conda-forge

## this new conda env comes with python3.12

## let's see if this works for our spatial analysis


conda activate
conda create -n "spatialDirt" 
 
## let's think about spatial turnover in Sulari's community data

## first step would be to get a map. 

## we want to see where we sample, and visualize respiration 
## values across the landscape

conda deactivate

conda remove -n spatialDirt --all

conda create -n "spatialDirt" 

conda activate "spatialDirt" 
conda config --env --add channels conda-forge
conda config --env --set channel_priority strict

conda install python=3 geopandas

conda activate spatialDirt 

pip install rasterio

## we also need to be R up to speed...
## maybe do this outside of conda

conda deactivate

sudo R 

install.packages("BiocManager")
BiocManager::install("phyloseq")


## I think that took care of most of the complex installs

## oh wait, let's get the jupyter notebook setup going...

## how do we make sure that the jupyter behaves, stays in the 
## right python?

conda activate spatialDirt 

pip install notebook 

which jupyter ## looks like that work. Gets easier every year.

## and it looks like it is even keeping the R kernel from 
## my general environment. 

## to get a bash kernel on there? https://github.com/takluyver/bash_kernel

pip install bash_kernel
python -m bash_kernel.install


## okay, push through the old code. 
## put it on the jupyter notebook if it works

conda activate spatialDirt 
python
import pandas as pd
import geopandas as gpd
import matplotlib.pyplot as plt; plt.ion()
import os, rasterio
import rasterio.plot
import scipy.spatial as sp
from sklearn.linear_model import LinearRegression
import numpy as np
from scipy import stats
from matplotlib.patches import Patch
from matplotlib_scalebar.scalebar import ScaleBar


spatDir="/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/spatialAnalysis"
## ^different on laptop
os.chdir(spatDir)

## we just want a map of points right now:

## on officeComp
#sulariEnvCSV="/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/sulariData/Envt_Matrix.csv"
## on laptop
#sulariEnvCSV="/home/daniel/Documents/projects/fichtelgebirge_project/sulariArneSoils/fichtelgebirgeSoils/sulariData/Envt_Matrix.csv"

envData = pd.read_csv(sulariEnvCSV)
## get rid of spaces
envData.rename({"Sample ID":"SampleID"}, axis="columns", inplace=True)
## we need to clean up the plot.ID. Sulari recorded season in the plot IDs,
## using letter codes. Also she has one double sampling, with an underscore
envData['Plot.ID'] = envData['Plot.ID'].str.slice(0,5)

## let's get rid of decimals in the names, weird for python work:
envData.rename({"Plot.ID":"PlotID", 
       "soil.respiration":"soil_respiration",
              "Land.type":"Land_type"}, 
                axis="columns", inplace=True)

envData.head()

## so we don't have to repeat:
envData.to_csv('/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/spatialAnalysis/sulariEnv.csv', index=False)

envData.head()


envData = pd.read_csv('/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/spatialAnalysis/sulariEnv.csv', index_col='SampleID')
 

## if we need to drop controls
envData.drop([ "C1.1", "C1.2", "C2.1", "C2.2"], inplace=True)

## her otu table is really large:
##### R ###
library('phyloseq')
load("/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/sulariData/sularilogMin50ps.rda")
logMin50ps
comdat <- as.data.frame(otu_table(logMin50ps))
write.csv(comdat, file="/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/sulariData/comdat.csv")
############

## back in python

comData = pd.read_csv("/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/sulariData/comdat.csv", index_col=0)

comData.drop([ "C1.1", "C1.2", "C2.1", "C2.2"], inplace=True)

comData.head()

## the map below looks funny...looks like every forest plot has 
## a grassland under it...

dupsFilter = envData.Latitude.duplicated()
dupped = envData[dupsFilter].sort_values(by="Latitude")
dupped.groupby('Plot.ID').nunique()
envData.iloc[0:5,0:8]

## nope...looks okay

## we want a geodf...

plotPoints = gpd.points_from_xy( envData.Longitude, envData.Latitude, crs="EPSG:4326" )

sulariPlotsDF = gpd.GeoDataFrame(envData[[ 'PlotID', 'soil_respiration', 
                    'MBC', 'season', 'Land_type', 'pH', 'N', 'C']], geometry=plotPoints)

## to convert to UTM? looks like we are in zone 33
## looks like:
## EPSG:32633

sulariPlot_utm = sulariPlotsDF.to_crs('EPSG:32633')

sulariPlot_utm.tail()

## can we import our georeferenced tif of the study area?
## lat/lon
#fichtelMap = rasterio.open("studyAreaClipped_modified.tif")
## UTM

fichtelMap = rasterio.open("studyAreaClipped_UTM.tif")

## color code our points according to land type?
cdik={
"Arableland":"b",
"Grassland":"y",
"Forest":"g",
}
sulariPlotsDF['landColors'] = [ cdik[i] for i in sulariPlotsDF['Land_type'] ]
sulariPlot_utm['landColors'] = [ cdik[i] for i in sulariPlotsDF['Land_type'] ]

fig, ax = plt.subplots()
rasterio.plot.show(fichtelMap, ax=ax)
sulariPlot_utm.plot(
    marker="o",
    ax=ax,
    edgecolor='k',
    facecolor=sulariPlotsDF['landColors'],
    markersize=400) 


grassPatch = Patch(color='y', label='grassland',)
forestPatch = Patch(color='g', label='forest')
farmPatch = Patch(color='b', label='arable land')
ax.legend(handles=[grassPatch, forestPatch, farmPatch], 
          loc="lower left",
          fontsize=15,
)

## if we want to compare just grassland and forest

plt.close('all')
onlyGrassForest = sulariPlot_utm[sulariPlot_utm['Land.type'].apply(lambda x: x in ["Forest", "Grassland"])]
fig, ax = plt.subplots()
rasterio.plot.show(fichtelMap, ax=ax)
onlyGrassForest.plot(
    marker="o",
    ax=ax,
    edgecolor='k',
    linewidths=2,
    facecolor=onlyGrassForest['landColors'],
    markersize=200) 
ax.ticklabel_format(style='plain', axis='y', useOffset=False)
grassPatch = Patch(color='y', label='grassland',)
forestPatch = Patch(color='g', label='forest')
ax.legend(handles=[grassPatch, forestPatch], loc='lower left')
ax.add_artist(ScaleBar(1, location='lower right')) 
ax.set_xlim([265500, 286930])
ax.set_ylim([5547227, 5570000])
plt.savefig('forestVsGrasslandMapUTM.png', dpi=600, format='png')

## Look at the turnover data:

## lat/long
aa = pd.DataFrame({'xx':envData.Longitude, 'yy':envData.Latitude})
physDist = sp.distance.pdist(aa, metric='euclidean')
bcDist = sp.distance.pdist(comData, metric='brayCurtis')
fig, ax = plt.subplots()
ax.scatter(physDist, bcDist)
X, Y = physDist.reshape(-1,1), bcDist.reshape(-1,1)
ax.plot( X, LinearRegression().fit(X, Y).predict(X), c='k')
ax.set_title(label="Turnover with Lat/Lon", loc='center')

## utms
aa = pd.DataFrame({'xx':sulariPlot_utm.geometry.x, 'yy':sulariPlot_utm.geometry.y})
physDist = sp.distance.pdist(aa, metric='euclidean')
bcDist = sp.distance.pdist(comData, metric='brayCurtis')
fig, ax = plt.subplots()
ax.scatter(physDist, bcDist)
X, Y = physDist.reshape(-1,1), bcDist.reshape(-1,1)
ax.plot( X, LinearRegression().fit(X, Y).predict(X), c='k')
ax.set_title(label="Turnover with UTM", loc='center')

plt.close('all')
## subset by landtype
for lt in [ "Arableland" ,"Grassland" ,"Forest"]: 
    print(lt)
    edf = envData[envData['Land.type'] == lt]
    cdf = comData.loc[edf.index]
    aa = pd.DataFrame({'xx':edf.Longitude, 'yy':edf.Latitude})
    aa = aa.iloc[0:120,:]
    physDist = sp.distance.pdist(aa, metric='euclidean')
    bcDist = sp.distance.pdist(cdf, metric='brayCurtis')
    fig, ax = plt.subplots()
    ax.scatter(physDist, bcDist)
    ax.set_title(lt)
    ax.set_title(label= (lt + " in degrees"), loc='center')
    X, Y = physDist.reshape(-1,1), bcDist.reshape(-1,1)
    ax.plot( X, LinearRegression().fit(X, Y).predict(X), c='k')

## well that looks pretty much like I hypothesized
## good stuff.

sulariPlot_utm.head()

plt.close('all')
plt.rc('ytick', labelsize=15)
plt.rc('xtick', labelsize=15)
lts = [ "Arableland" ,"Grassland" ,"Forest"]
#lts = [ "Grassland" ,"Forest"]
fig, axes = plt.subplots(nrows=1, ncols=len(lts), sharey=True)
axes = axes.flatten()
for nu,lt in enumerate(lts):
    edf = sulariPlot_utm[sulariPlot_utm['Land.type'] == lt]
    cdf = comData.loc[edf.index]
    aa = pd.DataFrame({'xx':edf.geometry.x, 'yy':edf.geometry.y})
    physDist = sp.distance.pdist(aa, metric='euclidean')
    bcDist = sp.distance.pdist(cdf, metric='brayCurtis')
    axes[nu].scatter(physDist, bcDist)
    X, Y = physDist.reshape(-1,1), bcDist.reshape(-1,1)
    linMod =  LinearRegression().fit(X, Y)
    axes[nu].plot( X, linMod.predict(X), c='k')
    axes[nu].set_title(label=lt, size=20, loc='center')
    axes[nu].set_xlabel('meters', size=20)
    print(lt, stats.linregress(physDist,bcDist))

fig.suptitle("Turnover in prokaryotic community", size=40)
axes[0].set_ylabel('Bray-Curtis dissimilarity', size=20)
axes[1].tick_params(left=False, labelleft=False, right=True, labelright=True, color='red', axis='y')
plt.subplots_adjust(wspace = 0)


###################################
##
## outputs from stats.regress:
##
## Arable Land
## slope=2.810886008879358e-06
## intercept=0.5742255266887248
## rvalue=0.07906122967379002
## pvalue=0.02033328808278514
## stderr=1.209265073980233e-06
## intercept_stderr=0.013364930035836518
## 
## Grassland
## slope=4.135586933082137e-07
## intercept=0.5590568736859212
## rvalue=0.012708447690178782
## pvalue=0.7298157896065798
## stderr=1.1969812747713313e-06
## intercept_stderr=0.013504959623407586
## 
## Forest
## slope=5.843245351182221e-06
## intercept=0.6024952517397398
## rvalue=0.20458396890349276
## pvalue=1.918646699083231e-08
## stderr=1.0284330215725841e-06
## intercept_stderr=0.01259259776931045
######################################

## add in the correlation coefficients and pvalues to grant app graphic. 

###### SAC curves ##########

## we have to stop avoiding gamma diversity calculations...

## do this in vegan? why not.

R

spatDir <- "/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/spatialAnalysis"
setwd(spatDir)


library(vegan)
library(phyloseq)

comM <- read.csv('/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/sulariData/comdat.csv', 
                    row.names=1)

## why is this so big, btw?

sum(colSums(comM) > 0) ## 4363. Why do we have a bunch of empty colums? I think these were low abundance ASVs, below our cutoffs.

## get rid of them to save memory:

library('phyloseq')
load("/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/sulariData/sularilogMin50ps.rda")

logMin50ps

comdat <- as.data.frame(otu_table(logMin50ps))
comdat = comdat[,colSums(comdat) > 0] 

write.csv(comdat, file="/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/sulariData/comdat.csv")


## get rid of controls
notControls=!(row.names(comM) %in% c("C1.1", "C1.2", "C2.1", "C2.2"))
comM = comM[notControls,]

comM[1:4,1:4]


sp1 <- specaccum(comM)

plot(sp1, ci.type="poly", col="blue", lwd=2, ci.lty=0, ci.col="lightblue")

specpool(comM)

sp2 <- specaccum(comM, "random")

summary(sp2)

plot(sp2, ci.type="poly", col="red", lwd=2, ci.lty=0, ci.col="pink")


data(BCI)

sp1 <- specaccum(BCI)


sp2 <- specaccum(BCI, "random")

sp2

summary(sp2)

plot(sp1, ci.type="poly", col="blue", lwd=2, ci.lty=0, ci.col="lightblue")
boxplot(sp2, col="yellow", add=TRUE, pch="+")
## Fit Lomolino model to the exact accumulation
mod1 <- fitspecaccum(sp1, "lomolino")
coef(mod1)
fitted(mod1)
plot(sp1)

aa <- specaccum(comM, method = "exact")

?specaccum

anaSAC <- data.frame(aa$richness, aa$sd)
colnames(anaSAC) <- c('richness', 'sd')
anaSpeciesEstimators = specpool(comM)
print(anaSpeciesEstimators)
 
## okay, but we need to separate out by land types.
## wish we were in python...

spatDir <- "/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/spatialAnalysis"
setwd(spatDir)
library(vegan)
library(phyloseq)

comData=read.csv("/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/sulariData/comdat.csv", row.names=1)
envData=read.csv("/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/spatialAnalysis/sulariEnv.csv", row.names=1)

all(row.names(comData) == row.names(envData))

lt <- 'Forest'
justThisLandtype=row.names(envData[envData['Land_type'] == lt,])
aa <- comData[ justThisLandtype,]
sp1 <- specaccum(aa)
plot(sp1, ci.type="poly", col="blue", lwd=2, ci.lty=0, ci.col="lightblue")


## so loop this:

for (lt in c('Arableland','Grassland', 'Forest')){
    print(lt)
    justThisLandtype=row.names(envData[envData['Land_type'] == lt,])
    comm.i <- comData[ justThisLandtype,]
    specAccum.i <- specaccum(comm.i)
    SACdf.i <- data.frame(specAccum.i$richness, specAccum.i$sd)
    colnames(SACdf.i) <- c('richness', 'sd')
    speciesEstimators.i = specpool(comm.i)
    print(speciesEstimators.i)
    write.csv(SACdf.i, file=paste(lt, "SAC.csv", sep="_"))
    write.csv(speciesEstimators.i, file=paste(lt, "specEst.csv", sep="_"))
}

## interesting, this is pretty much exactly what Brendan found
## in the amazon. Despite lower alpha diversity, higher beta 
## diversity in forest soils. 
## and this equates to a higher total diversity across the
## survey (gamma). 

## take over to python for plotting

## we have an old function for this, wonder if it still works:

######## original #######
def plotSACs(habtype, color='black',
                xUnits='ha', printChao=False,
                printTitle=False, ax=None):
    if ax is None: fig, ax = plt.subplots()
    sacName = (habtype +'_SAC.csv')
    specEstName = (habtype + "_specEst.csv")
    sacs = [ i for i in os.listdir() if "_SAC.csv" in i  ]
    assert( (habtype +'_SAC.csv') in sacs)
    assert( xUnits in ['ha','plots'])
    sac_i = pd.read_csv(sacName, index_col=0)
    pArea = np.pi * (30/2)**2 / 10000
    sac_i['areaSampled'] = (sac_i.index * pArea).to_list()
    if xUnits == 'ha': X = sac_i['areaSampled']
    elif xUnits == 'plots': X = sac_i.index.to_list()
    specEst_i = pd.read_csv(specEstName, index_col=0).loc['All']
    specEst_i.index = specEst_i.index.str.replace(".","_")
    ax.plot(X, sac_i['richness'], color=color)
    ax.fill_between(x=X,
                     y1=sac_i.richness - sac_i.sd,
                     y2=sac_i.richness + sac_i.sd,
                    alpha=0.4,
                    color=color,
                    )
    if printTitle: ax.set_title(f'{habtype}')
    if printChao:
        ax.text(1, (sac_i['richness'].max()-3),
                    f'Expected species richness = {specEst_i.chao.round()} +/- {specEst_i.chao_se.round()}',
            )
###########################################################3

os.chdir("/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/spatialAnalysis")

sacs = [ i for i in os.listdir() if "_SAC.csv" in i  ]

def plotSACs(habtype, color='black', ax=None):
    if ax is None: fig, ax = plt.subplots()
    sacs = [ i for i in os.listdir() if "_SAC.csv" in i  ]
    sacName = (habtype +'_SAC.csv')
    assert( (habtype +'_SAC.csv') in sacs)
    specEstName = (habtype + "_specEst.csv")
    sac_i = pd.read_csv(sacName, index_col=0)
    specEst_i = pd.read_csv(specEstName, index_col=0).loc['All']
    specEst_i.index = specEst_i.index.str.replace(".","_")
    X = sac_i.index
    ax.plot(X, sac_i['richness'], color=color)
    ax.fill_between(x=X,
                     y1=sac_i.richness - sac_i.sd,
                     y2=sac_i.richness + sac_i.sd,
                    alpha=0.4,
                    color=color,
                    )

plt.close('all')
fig, ax = plt.subplots(figsize=(10,10))
plotSACs('Arableland', ax=ax, color='#862d2d')
plotSACs('Forest', ax=ax, color='#006600')
plotSACs('Grassland', ax=ax, color='#1aff1a')



color="#E41A1C"
habtype="Grassland"
sacs = [ i for i in os.listdir() if "_SAC.csv" in i  ]
sacName = (habtype +'_SAC.csv')
assert( (habtype +'_SAC.csv') in sacs)
specEstName = (habtype + "_specEst.csv")
sac_i = pd.read_csv(sacName, index_col=0)
specEst_i = pd.read_csv(specEstName, index_col=0).loc['All']
specEst_i.index = specEst_i.index.str.replace(".","_")
X = sac_i.index
ax.plot(X, sac_i['richness'], color=color)
ax.fill_between(x=X,
                 y1=sac_i.richness - sac_i.sd,
                 y2=sac_i.richness + sac_i.sd,
                alpha=0.4,
                color=color,
                )




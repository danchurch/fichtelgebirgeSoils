## git our local copy of the repo in order for office comp.
## working off the work tower, so need to get git synced up now to
## avoid confusion.

## we need RSA with SHA-2 signature algorithm

man ssh-keygen
ssh-keygen -t rsa -f fuj2git

## now, what do we need to get the push functionality...

git clone https://github.com/danchurch/fichtelgebirgeSoils.git

## test

touch thisIsNotReal.txt

## and of course can't push

git config --global user.email "danchurchthomas@gmail.com"
git config --global user.name "danchurch"

git remote add origin https://github.com/danchurch/fichtelgebirgeSoils.git
git branch -M main
git remote set-url origin git@github.com:danchurch/fichtelgebirgeSoils.git
git push -u origin main

## and we're in business with github

## maybe let's get a conda environment going for this.

wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh

mkdir -p ~/miniconda3
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh
bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3
rm -rf ~/miniconda3/miniconda.sh
~/miniconda3/bin/conda init bash

conda config --set auto_activate_base false

## get the mamba solver:

conda update -n base conda
conda install -n base conda-libmamba-solver
conda config --set solver libmamba

## get the standard channels
conda config --add channels defaults
conda config --add channels bioconda
conda config --add channels conda-forge

## this new conda env comes with python3.12

## let's see if this works for our spatial analysis


conda activate
conda create -n "spatialDirt" 
 
## let's think about spatial turnover in Sulari's community data

## first step would be to get a map. 

## we want to see where we sample, and visualize respiration 
## values across the landscape

conda deactivate

conda remove -n spatialDirt --all

conda create -n "spatialDirt" 

conda activate "spatialDirt" 
conda config --env --add channels conda-forge
conda config --env --set channel_priority strict

conda install python=3 geopandas

conda activate spatialDirt 

pip install rasterio

## we also need to be R up to speed...
## maybe do this outside of conda

conda deactivate

sudo R 

install.packages("BiocManager")
BiocManager::install("phyloseq")


## I think that took care of most of the complex installs

## oh wait, let's get the jupyter notebook setup going...

## how do we make sure that the jupyter behaves, stays in the 
## right python?

conda activate spatialDirt 

pip install notebook 

which jupyter ## looks like that work. Gets easier every year.

## and it looks like it is even keeping the R kernel from 
## my general environment. 

## to get a bash kernel on there? https://github.com/takluyver/bash_kernel

pip install bash_kernel
python -m bash_kernel.install


##### bayesian setup #####

## last time we worked with pymc3 we needed
## a separate conda env. Let's see if 
## things have gotten better. 

## first back up the env, just in case

conda activate spatialDirt

conda env export > spatialDirt.yml

## installing bambi should also install pymc, so
## try the bambi conda installs as per: 
https://github.com/bambinos/bambi#quickstart

pip install bambi

pip install "preliz[full,lab]"

## get the data from the newest martin book.

## put outside our repo

cd /home/daniel/Documents/manualsBooks/bayesian
git clone https://github.com/aloctavodia/BAP3.git

## seems like that worked in our spatialDirt environment

## try everything out for a bit, then update yaml backup for the repo


conda activate spatialDirt 

python

import pandas as pd
import geopandas as gpd
import matplotlib.pyplot as plt; plt.ion()
import os, rasterio
import rasterio.plot
import scipy.spatial as sp
from sklearn.linear_model import LinearRegression
import numpy as np
from scipy import stats
from matplotlib.patches import Patch
from matplotlib_scalebar.scalebar import ScaleBar
import pymc as pm


spatDir="/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/spatialAnalysis"
## ^different on laptop
os.chdir(spatDir)

## we just want a map of points right now:

## on officeComp
#sulariEnvCSV="/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/sulariData/Envt_Matrix.csv"
## on laptop
#sulariEnvCSV="/home/daniel/Documents/projects/fichtelgebirge_project/sulariArneSoils/fichtelgebirgeSoils/sulariData/Envt_Matrix.csv"

envData = pd.read_csv(sulariEnvCSV)
## get rid of spaces
envData.rename({"Sample ID":"SampleID"}, axis="columns", inplace=True)
## we need to clean up the plot.ID. Sulari recorded season in the plot IDs,
## using letter codes. Also she has one double sampling, with an underscore
envData['Plot.ID'] = envData['Plot.ID'].str.slice(0,5)

## let's get rid of decimals in the names, weird for python work:
envData.rename({"Plot.ID":"PlotID", 
       "soil.respiration":"soil_respiration",
              "Land.type":"Land_type"}, 
                axis="columns", inplace=True)

envData.head()

## so we don't have to repeat:
envData.to_csv('/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/spatialAnalysis/sulariEnv.csv', index=False)

envData.head()


envData = pd.read_csv('/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/spatialAnalysis/sulariEnv.csv', index_col='SampleID')
 

## if we need to drop controls
envData.drop([ "C1.1", "C1.2", "C2.1", "C2.2"], inplace=True)

## her otu table is really large:
##### R ###
library('phyloseq')
load("/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/sulariData/sularilogMin50ps.rda")
logMin50ps
comdat <- as.data.frame(otu_table(logMin50ps))
write.csv(comdat, file="/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/sulariData/comdat.csv")
############

## back in python

comData = pd.read_csv("/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/sulariData/comdat.csv", index_col=0)

comData.drop([ "C1.1", "C1.2", "C2.1", "C2.2"], inplace=True)

comData.head()

## the map below looks funny...looks like every forest plot has 
## a grassland under it...

dupsFilter = envData.Latitude.duplicated()
dupped = envData[dupsFilter].sort_values(by="Latitude")
dupped.groupby('Plot.ID').nunique()
envData.iloc[0:5,0:8]

## nope...looks okay

## we want a geodf...

plotPoints = gpd.points_from_xy( envData.Longitude, envData.Latitude, crs="EPSG:4326" )

sulariPlotsDF = gpd.GeoDataFrame(envData[[ 'PlotID', 'soil_respiration', 
                    'MBC', 'season', 'Land_type', 'pH', 'N', 'C']], geometry=plotPoints)

## to convert to UTM? looks like we are in zone 33
## looks like:
## EPSG:32633

sulariPlot_utm = sulariPlotsDF.to_crs('EPSG:32633')

sulariPlot_utm.tail()

## can we import our georeferenced tif of the study area?
## lat/lon
#fichtelMap = rasterio.open("studyAreaClipped_modified.tif")
## UTM

fichtelMap = rasterio.open("studyAreaClipped_UTM.tif")

## color code our points according to land type?
cdik={
"Arableland":"b",
"Grassland":"y",
"Forest":"g",
}
sulariPlotsDF['landColors'] = [ cdik[i] for i in sulariPlotsDF['Land_type'] ]
sulariPlot_utm['landColors'] = [ cdik[i] for i in sulariPlotsDF['Land_type'] ]

fig, ax = plt.subplots()
rasterio.plot.show(fichtelMap, ax=ax)
sulariPlot_utm.plot(
    marker="o",
    ax=ax,
    edgecolor='k',
    facecolor=sulariPlotsDF['landColors'],
    markersize=400) 


grassPatch = Patch(color='y', label='grassland',)
forestPatch = Patch(color='g', label='forest')
farmPatch = Patch(color='b', label='arable land')
ax.legend(handles=[grassPatch, forestPatch, farmPatch], 
          loc="lower left",
          fontsize=15,
)

## if we want to compare just grassland and forest

plt.close('all')
onlyGrassForest = sulariPlot_utm[sulariPlot_utm['Land.type'].apply(lambda x: x in ["Forest", "Grassland"])]
fig, ax = plt.subplots()
rasterio.plot.show(fichtelMap, ax=ax)
onlyGrassForest.plot(
    marker="o",
    ax=ax,
    edgecolor='k',
    linewidths=2,
    facecolor=onlyGrassForest['landColors'],
    markersize=200) 
ax.ticklabel_format(style='plain', axis='y', useOffset=False)
grassPatch = Patch(color='y', label='grassland',)
forestPatch = Patch(color='g', label='forest')
ax.legend(handles=[grassPatch, forestPatch], loc='lower left')
ax.add_artist(ScaleBar(1, location='lower right')) 
ax.set_xlim([265500, 286930])
ax.set_ylim([5547227, 5570000])
plt.savefig('forestVsGrasslandMapUTM.png', dpi=600, format='png')

## Look at the turnover data:

## lat/long
aa = pd.DataFrame({'xx':envData.Longitude, 'yy':envData.Latitude})
physDist = sp.distance.pdist(aa, metric='euclidean')
bcDist = sp.distance.pdist(comData, metric='brayCurtis')
fig, ax = plt.subplots()
ax.scatter(physDist, bcDist)
X, Y = physDist.reshape(-1,1), bcDist.reshape(-1,1)
ax.plot( X, LinearRegression().fit(X, Y).predict(X), c='k')
ax.set_title(label="Turnover with Lat/Lon", loc='center')

## utms
aa = pd.DataFrame({'xx':sulariPlot_utm.geometry.x, 'yy':sulariPlot_utm.geometry.y})
physDist = sp.distance.pdist(aa, metric='euclidean')
bcDist = sp.distance.pdist(comData, metric='brayCurtis')
fig, ax = plt.subplots()
ax.scatter(physDist, bcDist)
X, Y = physDist.reshape(-1,1), bcDist.reshape(-1,1)
ax.plot( X, LinearRegression().fit(X, Y).predict(X), c='k')
ax.set_title(label="Turnover with UTM", loc='center')

plt.close('all')
## subset by landtype
for lt in [ "Arableland" ,"Grassland" ,"Forest"]: 
    print(lt)
    edf = envData[envData['Land.type'] == lt]
    cdf = comData.loc[edf.index]
    aa = pd.DataFrame({'xx':edf.Longitude, 'yy':edf.Latitude})
    aa = aa.iloc[0:120,:]
    physDist = sp.distance.pdist(aa, metric='euclidean')
    bcDist = sp.distance.pdist(cdf, metric='brayCurtis')
    fig, ax = plt.subplots()
    ax.scatter(physDist, bcDist)
    ax.set_title(lt)
    ax.set_title(label= (lt + " in degrees"), loc='center')
    X, Y = physDist.reshape(-1,1), bcDist.reshape(-1,1)
    ax.plot( X, LinearRegression().fit(X, Y).predict(X), c='k')

## well that looks pretty much like I hypothesized
## good stuff.

sulariPlot_utm.head()

plt.close('all')
plt.rc('ytick', labelsize=15)
plt.rc('xtick', labelsize=15)
lts = [ "Arableland" ,"Grassland" ,"Forest"]
#lts = [ "Grassland" ,"Forest"]
fig, axes = plt.subplots(nrows=1, ncols=len(lts), sharey=True)
axes = axes.flatten()
for nu,lt in enumerate(lts):
    edf = sulariPlot_utm[sulariPlot_utm['Land.type'] == lt]
    cdf = comData.loc[edf.index]
    aa = pd.DataFrame({'xx':edf.geometry.x, 'yy':edf.geometry.y})
    physDist = sp.distance.pdist(aa, metric='euclidean')
    bcDist = sp.distance.pdist(cdf, metric='brayCurtis')
    axes[nu].scatter(physDist, bcDist)
    X, Y = physDist.reshape(-1,1), bcDist.reshape(-1,1)
    linMod =  LinearRegression().fit(X, Y)
    axes[nu].plot( X, linMod.predict(X), c='k')
    axes[nu].set_title(label=lt, size=20, loc='center')
    axes[nu].set_xlabel('meters', size=20)
    print(lt, stats.linregress(physDist,bcDist))

fig.suptitle("Turnover in prokaryotic community", size=40)
axes[0].set_ylabel('Bray-Curtis dissimilarity', size=20)
axes[1].tick_params(left=False, labelleft=False, right=True, labelright=True, color='red', axis='y')
plt.subplots_adjust(wspace = 0)


###################################
##
## outputs from stats.regress:
##
## Arable Land
## slope=2.810886008879358e-06
## intercept=0.5742255266887248
## rvalue=0.07906122967379002
## pvalue=0.02033328808278514
## stderr=1.209265073980233e-06
## intercept_stderr=0.013364930035836518
## 
## Grassland
## slope=4.135586933082137e-07
## intercept=0.5590568736859212
## rvalue=0.012708447690178782
## pvalue=0.7298157896065798
## stderr=1.1969812747713313e-06
## intercept_stderr=0.013504959623407586
## 
## Forest
## slope=5.843245351182221e-06
## intercept=0.6024952517397398
## rvalue=0.20458396890349276
## pvalue=1.918646699083231e-08
## stderr=1.0284330215725841e-06
## intercept_stderr=0.01259259776931045
######################################

## add in the correlation coefficients and pvalues to grant app graphic. 

###### SAC curves ##########

## we have to stop avoiding gamma diversity calculations...

## do this in vegan? why not.

R

spatDir <- "/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/spatialAnalysis"
setwd(spatDir)


library(vegan)
library(phyloseq)

comM <- read.csv('/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/sulariData/comdat.csv', 
                    row.names=1)

## why is this so big, btw?

sum(colSums(comM) > 0) ## 4363. Why do we have a bunch of empty colums? I think these were low abundance ASVs, below our cutoffs.

## get rid of them to save memory:

library('phyloseq')
load("/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/sulariData/sularilogMin50ps.rda")

logMin50ps

comdat <- as.data.frame(otu_table(logMin50ps))
comdat = comdat[,colSums(comdat) > 0] 

write.csv(comdat, file="/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/sulariData/comdat.csv")


## get rid of controls
notControls=!(row.names(comM) %in% c("C1.1", "C1.2", "C2.1", "C2.2"))
comM = comM[notControls,]

comM[1:4,1:4]


sp1 <- specaccum(comM)

plot(sp1, ci.type="poly", col="blue", lwd=2, ci.lty=0, ci.col="lightblue")

specpool(comM)

sp2 <- specaccum(comM, "random")

summary(sp2)

plot(sp2, ci.type="poly", col="red", lwd=2, ci.lty=0, ci.col="pink")


data(BCI)

sp1 <- specaccum(BCI)


sp2 <- specaccum(BCI, "random")

sp2

summary(sp2)

plot(sp1, ci.type="poly", col="blue", lwd=2, ci.lty=0, ci.col="lightblue")
boxplot(sp2, col="yellow", add=TRUE, pch="+")
## Fit Lomolino model to the exact accumulation
mod1 <- fitspecaccum(sp1, "lomolino")
coef(mod1)
fitted(mod1)
plot(sp1)

aa <- specaccum(comM, method = "exact")

?specaccum

anaSAC <- data.frame(aa$richness, aa$sd)
colnames(anaSAC) <- c('richness', 'sd')
anaSpeciesEstimators = specpool(comM)
print(anaSpeciesEstimators)
 
## okay, but we need to separate out by land types.
## wish we were in python...

spatDir <- "/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/spatialAnalysis"
setwd(spatDir)
library(vegan)
library(phyloseq)

comData=read.csv("/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/sulariData/comdat.csv", row.names=1)
envData=read.csv("/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/spatialAnalysis/sulariEnv.csv", row.names=1)

all(row.names(comData) == row.names(envData))

lt <- 'Forest'
justThisLandtype=row.names(envData[envData['Land_type'] == lt,])
aa <- comData[ justThisLandtype,]
sp1 <- specaccum(aa)
plot(sp1, ci.type="poly", col="blue", lwd=2, ci.lty=0, ci.col="lightblue")


## so loop this:

for (lt in c('Arableland','Grassland', 'Forest')){
    print(lt)
    justThisLandtype=row.names(envData[envData['Land_type'] == lt,])
    comm.i <- comData[ justThisLandtype,]
    specAccum.i <- specaccum(comm.i)
    SACdf.i <- data.frame(specAccum.i$richness, specAccum.i$sd)
    colnames(SACdf.i) <- c('richness', 'sd')
    speciesEstimators.i = specpool(comm.i)
    print(speciesEstimators.i)
    write.csv(SACdf.i, file=paste(lt, "SAC.csv", sep="_"))
    write.csv(speciesEstimators.i, file=paste(lt, "specEst.csv", sep="_"))
}

## interesting, this is pretty much exactly what Brendan found
## in the amazon. Despite lower alpha diversity, higher beta 
## diversity in forest soils. 
## and this equates to a higher total diversity across the
## survey (gamma). 

## take over to python for plotting

## we have an old function for this, wonder if it still works:


os.chdir("/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/spatialAnalysis")

sacs = [ i for i in os.listdir() if "_SAC.csv" in i  ]

def plotSACs(habtype, color='black', ax=None):
    if ax is None: fig, ax = plt.subplots()
    sacs = [ i for i in os.listdir() if "_SAC.csv" in i  ]
    sacName = (habtype +'_SAC.csv')
    assert( (habtype +'_SAC.csv') in sacs)
    specEstName = (habtype + "_specEst.csv")
    sac_i = pd.read_csv(sacName, index_col=0)
    specEst_i = pd.read_csv(specEstName, index_col=0).loc['All']
    specEst_i.index = specEst_i.index.str.replace(".","_")
    X = sac_i.index
    ax.plot(X, sac_i['richness'], color=color)
    ax.fill_between(x=X,
                     y1=sac_i.richness - sac_i.sd,
                     y2=sac_i.richness + sac_i.sd,
                    alpha=0.4,
                    color=color,
                    )

plt.close('all')
fig, ax = plt.subplots(figsize=(10,10))
plotSACs('Arableland', ax=ax, color='#862d2d')
plotSACs('Forest', ax=ax, color='#006600')
plotSACs('Grassland', ax=ax, color='#FF7F00')

Arableland_patch = Patch(color='#862d2d', label='Arableland', alpha=0.4)
Forest_patch = Patch(color='#006600', label='Forest', alpha=0.4)
Grassland_patch = Patch(color='#FF7F00', label='Grassland', alpha=0.4)

ax.legend(handles=[Forest_patch, Arableland_patch, Grassland_patch])
ax.set_title('Species accumulution curves by\nland-use/Habitat')
ax.set_xlabel('Sites sampled')
ax.set_ylabel('Prokaryotic ASVs')


[Arableland_patch, Forest_patch, Grassland_patch]

## repeat alpha diversity
## using our >50 reads OTU table, can we calculate alpha diveristy by land type?
## back to old fashioned vegan/R

## we just want species richness. So we need to rarefy and compare 
## forest v. farm v. grassland data

notControls=!(row.names(comData) %in% c("C1.1", "C1.2", "C2.1", "C2.2"))
comData = comData[notControls,]
envData = envData[notControls,]

data(BCI)

S <- specnumber(BCI) # observed number of species

S <- specnumber(comData) # observed number of species

## pretty much same as:
aa <- comData
aa[aa > 0] <- 1
rowSums(aa)

S <- specnumber(comData) # observed number of species

(raremax <- min(rowSums(BCI)))

Srare <- rarefy(BCI, raremax)

plot(S, Srare, xlab = "Observed No. of Species", ylab = "Rarefied No. of Species")

abline(0, 1)

rarecurve(BCI, step = 20, sample = raremax, col = "blue", cex = 0.6)


## so we are looking for a rarified species richness for each site.

## from this we will generate 3 mean +/- error values of species richness 
## one for each land use.

## this kind of analysis is really ok for count data.
## we've done all kinds of transformations, to try 
## to reduce sequencer error. 

## so I think we need to back up to phyloseq, to use our 
## sequencing depth information

library(phyloseq)


## transformed:
load("/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/sulariData/sularilogMin50ps.rda")

## not transformed:
load("/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/sulariData/sulariPhyloseqObject.rda")

logMin50ps

(p = plot_richness(ps, x = "Land.type"))

estimate_richness(ps)

estimate_richness

## but I am thinking about this incorrectly. 
## these richness estimates are way high, 
## because of PCR, sequencer error, etc. 

## we attempting to reign in these errors 
## a bit through our transformations, let's
## honor this. 

## so back and use our communty matrix, 

savehistory("/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/spatialAnalysis/latelyInR.txt")

## to make it into "count data", multiply 
## to get rid of decimals:


sum(comData < .001 & comData > 0) ## 508 observations smaller than .001.
sum(comData < .0001 & comData > 0) ## 0 observations, so let's multiply by 10000
comDataFakeCounts = ceiling(comData * 10000) 
min(comDataFakeCounts[ comDataFakeCounts > 0 ]) ## our smallest non-zero observation is 8 

S <- specnumber(comDataFakeCounts) # observed number of species

(raremax <- min(rowSums(comDataFakeCounts))) ## 10001

rowSums(comDataFakeCounts)

Srare <- rarefy(comDataFakeCounts, raremax) ## this is what we need. 

## this is an estimate of how many species are present in each 
## sample, after coming down to a minimum abundance


## kind of interesting but not useful. Shows we sequenced deeply enough:
plot(S, Srare, xlab = "Observed No. of Species", ylab = "Rarefied No. of Species")

## can we do all that without transforming to "counts"?
S2 <- specnumber(comData) # observed number of species, same as fake counts

(raremax2 <- min(rowSums(comData))) ## .9896

rowSums(comData)



## compare to:

bb <- specnumber(comData) # observed number of species
all(bb == Srare) ## yes. the same
## So I guess I am brilliant, I just reinvented their command. 
## big waste of time. 

## maybe also shows there isn't really a need to rarefy, at least
## on the transformed data

## not sure, but now let's trust these numbers.

## now, subset by land type, and get means?

head(envData)

all(row.names(envData) == row.names(comData))

## I'd guess we need a vector of group names (by land_type):
hist(Srare, 20) ## looks more or less normal.
mean(Srare) ## 301.3833
sd(Srare) ## 26.4

print("mean alpha diversity of all sites = ", mean(Srare))

print(paste("mean alpha diversity of all sites =", mean(Srare), "ASVs"))

cat(paste("mean alpha diversity of all sites =", mean(Srare), "ASVs"))

cat(paste("mean alpha diversity of all sites =", mean(Srare), "+/-", round(sd(Srare)), "ASVs"))


all(names(Srare) == row.names(envData))

## break this down by groups:

tapply(Srare, envData$Land_type, mean)
tapply(Srare, envData$Land_type, sd)

boxplot(Srare ~ envData$Land_type)

## anova
res.aov <- aov(Srare ~ envData$Land_type)
summary(res.aov) ## F= 2.85, p = 0.0618

## so maybe differences in species richness due to land type,
## maybe not.  Not a large effect, anyway. 
## update notebook, give it a break.

## t-test for difference between forest and grassland?

## to remove the farm samples 

noFarms <- envData$Land_type != "Arableland"

envData$Land_type[noFarms]
Srare[noFarms]


head(envData)

t.test(Srare[noFarms] ~ envData$Land_type[noFarms])

t_test(weight ~ group)

## we should probably do this in a bayesian way...
## get the ordinations done, then order the new book, 
## PCNMs can also be started without tests.

## but generally not sure how to handle the multivariate
## tests in a bayesian way. 

## two possibilities:
## BetaBayes: https://doi.org/10.3390/d14100858, somehow related to GDS
## BERA: https://doi.org/10.1080/00273171.2019.1598837
## BERA is apparently related to RDA. More reading is in order on both. 

## in the meantime...re-run the ordinations:

## the usual pipeline
## let's get ordinations with vegan and plot with python 

library(vegan)

spatDir <- "/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/spatialAnalysis"
setwd(spatDir)

comData=read.csv("/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/sulariData/comdat.csv", row.names=1)
envData=read.csv("/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/spatialAnalysis/sulariEnv.csv", row.names=1)
## get rid of controls
notControls=!(row.names(comData) %in% c("C1.1", "C1.2", "C2.1", "C2.2"))
comData <- comData[notControls,]
envData <- envData[notControls,]

comData[1:4,1:4]

comNMS <- metaMDS(comData, try=40)

write.csv(comNMS$points, file='comNMS.csv')

## check this out in python:

python
import pandas as pd
import matplotlib.pyplot as plt; plt.ion()
import matplotlib.colors 
import os
import scipy.spatial as sp
import numpy as np
from scipy import stats
from matplotlib.patches import Patch
import pymc as pm
import preliz as pz
import arviz as az

## data
nmsPts = pd.read_csv("comNMS.csv", index_col=0)
sulariEnvCSV="/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/spatialAnalysis/sulariEnv.csv"
envData = pd.read_csv(sulariEnvCSV, index_col='SampleID')
comData = pd.read_csv("/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/sulariData/comdat.csv", 
                      index_col=0) 
controls=[ 'C1.1', 'C1.2', 'C2.1', 'C2.2']
envData.drop(controls, axis='rows', inplace=True)
comData.drop(controls, axis='rows', inplace=True)

## need some colors for land type
colorDict = {
'Arableland':'#862d2d',
'Forest'    :'#006600',
'Grassland' :'#FF7F00'
}
landCols = [ colorDict[i] for i in envData['Land_type'] ]
plt.close('all')
fig, ax = plt.subplots()
ax.scatter(x=nmsPts["MDS1"],
           y=nmsPts["MDS2"], 
           c=landCols,
          )
Arableland_patch = Patch(color='#862d2d', label='Arableland')
Forest_patch = Patch(color='#006600', label='Forest')
Grassland_patch = Patch(color='#FF7F00', label='Grassland')
ax.legend(handles=[Forest_patch, Arableland_patch, Grassland_patch])

## try markers for seasonality?
seasonDict = {
     'S': "o", 
    'SP': "v", 
    'W1': "D", 
    'W2': "P", 
     'A': "s",
}

## we might also check pH, and seasonality, and microbial biomass

## seasonality:
seasonShapes = [ seasonDict[i] for i in envData['season'] ]

## matplot lib doesn't change markers on the fly...
## if we want to change markers for each season:

plt.close('all')
fig, ax = plt.subplots()
for i in envData.season.unique():
  print(i)
  env_i = envData[envData['season'] == i]
  plots_i = env_i.index.to_list()
  nmsPts_i = nmsPts.loc[plots_i]
  cols_i = [ colorDict[i] for i in env_i['Land_type'] ]
  ax.scatter(x=nmsPts_i["MDS1"],
             y=nmsPts_i["MDS2"], 
             c=cols_i,
        marker=seasonDict[i],
            )

## I don't see any evidence of seasonality affecting these
## community structures

## ph ordinations

## color by pH, land by symbol, respiration by size

landTypeShapesDict = {
'Arableland': "o", 
'Forest'    : "v", 
'Grassland' : "s", 
}

pHmin = envData['pH'].min() ## 3.647
pHmax = envData['pH'].max() ## 7.312
norm=matplotlib.colors.Normalize(pHmin, pHmax)
plt.close('all')
fig, ax = plt.subplots()
for i in envData.Land_type.unique():
  print(i)
  env_i = envData[envData['Land_type'] == i]
  plots_i = env_i.index.to_list()
  nmsPts_i = nmsPts.loc[plots_i]
  sizes = env_i['soil_respiration']*50
  ax.scatter(x=nmsPts_i["MDS1"],
             y=nmsPts_i["MDS2"], 
             #s=140,
             s=sizes,
             c=env_i['pH'],
             cmap='Spectral',
             edgecolors='black',
             marker=landTypeShapesDict[i],
             norm=norm,
            )

fig.colorbar(plt.cm.ScalarMappable(norm=matplotlib.colors.Normalize(pHmin, pHmax), cmap='Spectral'),
             ax=ax, orientation='vertical', label='pH')


## this is a good graph. needs a legend. 

## as usual, legends are beyond my ability. Do them manually later if we want the figure.


### test out bayesian setup, try comparison of two groups ###

dist = pz.Beta()
pz.maxent(dist, 0.1, 0.7, 0.9)

## test out the pymc3 setup:
np.random.seed(123)
trials = 4
theta_real = 0.35
data = pz.Binomial(n=1, p=theta_real).rvs(trials)

np.random.seed(123)
trials = 4
theta_real = 0.35
data = stats.bernoulli.rvs(p=theta_real, size=trials)

with pm.Model() as our_first_model:
    θ = pm.Beta('θ', alpha=1., beta=1.)
    γ = pm.Bernoulli('γ', p=θ, observed=data)
    trace = pm.sample(1000, random_seed=123)

## works. I can hardly remember how to do this bayesian stuff,
## but we can work from old examples....

## let's redo our only statistical model/test so far, the comparison 
## of alpha diversity between the land types

## start with oswaldo's tips example:

tips = pd.read_csv("/home/daniel/Documents/manualsBooks/bayesian/BAP3/code/data/tips.csv")

tips.tail()

categories = np.array(["Thur", "Fri", "Sat", "Sun"])
tip = tips["tip"].values
idx = pd.Categorical(tips["day"], categories=categories).codes

## arviz has cool plotting capabilities I have not even begun to learn:
az.plot_forest(tips.pivot(columns="day", values="tip").to_dict("list"),
               kind="ridgeplot",
               hdi_prob=1,
               colors="C1",
               figsize=(12, 4))

## for indexing with Arviz:

coords = {"days": categories, "days_flat":categories[idx]}

with pm.Model(coords=coords) as comparing_groups:
    μ = pm.HalfNormal("μ", sigma=5, dims="days")
    σ = pm.HalfNormal("σ", sigma=1, dims="days")
    y = pm.Gamma("y", mu=μ[idx], sigma=σ[idx], observed=tip, dims="days_flat")
    idata_cg = pm.sample(random_seed=4591, chains=4)
    idata_cg.extend(pm.sample_posterior_predictive(idata_cg, random_seed=4591))


_, axes = plt.subplots(2, 2, figsize=(10, 5), sharex=True, sharey=True)

az.plot_ppc(idata_cg, num_pp_samples=100,
            colors=["C1", "C0", "C0"],
            coords={"days_flat":[categories]}, flatten=[], ax=axes)

az.plot_trace(idata_cg)

plt.show()

## seems fine
az.summary(idata_cg, kind="stats").round(2)



## okay, how do we adapt this to our data? we want to compare 
## alpha diversity of three groups - crop, forest, and grassland.

sulariEnvCSV="/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/spatialAnalysis/sulariEnv.csv"
envData = pd.read_csv(sulariEnvCSV, index_col='SampleID')
comData = pd.read_csv("/home/daniel/Documents/projects/fichtelSoils/fichtelgebirgeSoils/sulariData/comdat.csv", 
                      index_col=0) 
controls=[ 'C1.1', 'C1.2', 'C2.1', 'C2.2']
envData.drop(controls, axis='rows', inplace=True)
comData.drop(controls, axis='rows', inplace=True)

## we observed above that we can trust the raw species 
## richness counts from our community matrix, no need
## to rarify back or anything. 

## so how to get this in pandas/python?

aa = comData.copy()
aa[aa > 0] = 1
specRich = aa.sum(axis="columns")

comData.head()

aa.head()

aa.sum(axis="columns")

aa.sum(axis="columns").loc['S14']

aa.sum(axis="columns").loc['S102']


specRich = aa.sum(axis="columns")



pd.to_numeric(specRich, downcast='integer')

## maybe a df with all the info we need:

specRichLT = (pd.concat([pd.to_numeric(specRich, downcast='integer'), envData['Land_type']], axis='columns')
                     .rename({0:"spRich"},axis="columns"))

## looks right. so this should be our species richness. Might need this later:
specRichLT.to_csv("specRich.csv")

specRichLT.head()

## we want to get a distribution for the mean values of alpha diversity for
## each group 
 
specRichLT.head()

## can we visualize this with arviz first?:

az.plot_forest(specRichLT.pivot(columns="Land_type", values="spRich").to_dict("list"),
               kind="ridgeplot",
               hdi_prob=1,
               colors="C1",
               figsize=(12, 4))

## oswaldo's confusing code for creating an index, adapted for our data:
categories = np.array(["Arableland", "Grassland", "Forest"])
spr = specRichLT["spRich"].values
idx = pd.Categorical(specRichLT["Land_type"], categories=categories).codes

coords = {"Land_type": categories, "land_type_flat":categories[idx]}

## not run - why gamma?
with pm.Model(coords=coords) as comparing_groups:
    μ = pm.HalfNormal("μ", sigma=5, dims="Land_type")
    σ = pm.HalfNormal("σ", sigma=1, dims="Land_type")
    y = pm.Gamma("y", mu=μ[idx], sigma=σ[idx], observed=spr, dims="Land_type_flat")
    idata_cg = pm.sample(random_seed=4591)
    idata_cg.extend(pm.sample_posterior_predictive(idata_cg, random_seed=4591))


